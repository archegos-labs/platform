{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fe65f9-698e-4f25-a292-7018be63e0e6",
   "metadata": {},
   "source": [
    "# Run Distributed PyTorch Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d66e9e-f016-4c0f-8b8d-51681607d381",
   "metadata": {},
   "source": [
    "This notebook uses the [Kubeflow training operator](https://www.kubeflow.org/docs/components/training/overview/) to run a distributed [PytorchJob](https://www.kubeflow.org/docs/components/training/user-guides/pytorch/) using [DistributedDataParallel strategy](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html) against the EKS cluster. We train a simple Convolutional Neural Network (CNN) that recognizes different pictures of clothing on the classic [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7968ba-8941-4f17-b41d-7e242112a591",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e1cbd-4bb0-4a46-b17e-6bb4ac2e451a",
   "metadata": {},
   "source": [
    "Install PyTorch packages and Kubeflow SDKs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5afd39-3914-46ad-8e4f-34d0cb3919c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98defdf6-ee76-4399-927f-2473d30dbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c190c6-c39e-4200-a2ed-5da29e2f968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/kubeflow/training-operator.git@master#subdirectory=sdk/python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37292346-e034-4973-ba56-4e1f247aa5b6",
   "metadata": {},
   "source": [
    "## Install AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee986304-9403-4c2b-88f0-fbea3f9de629",
   "metadata": {},
   "source": [
    "Used by our local kubeconfig which is likely configured to use an exec plugin that calls aws eks get-token to obtain authentication tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa6be3-cc11-4ed9-b5cf-370442dcefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"https://awscli.amazonaws.com/awscli-exe-linux-aarch64.zip\" -o ~/awscliv2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6bc89-abb3-45ce-89b2-e38c79131a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip ~/awscliv2.zip -d ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a305242-bbc5-465e-a2a5-76b735b00f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo ~/aws/install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6353b46e-281e-431d-b3a6-5d45efcbac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a342c3-fc02-4d32-bbc4-7e1557f546a4",
   "metadata": {},
   "source": [
    "## Install Kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad098fb-1e47-4e39-b6a1-3ffea3b5471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/arm64/kubectl\" -o ~/kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37960675-8fba-4f90-974c-cbfc04696c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo install -o root -g root -m 0755 ~/kubectl /usr/local/bin/kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721534b6-0b74-4963-9661-32881c900821",
   "metadata": {},
   "source": [
    "Now, let's validate the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11135d63-1e56-41eb-99f9-427adf8af1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl version --client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeacc79-584d-4567-84b4-b4380d7ebd40",
   "metadata": {},
   "source": [
    "## Create a Pytorch Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db6039-fa7e-4430-93ab-98dbe738de01",
   "metadata": {},
   "source": [
    "A pytorch job that, \n",
    "\n",
    "* Downloads the Fashion MNIST Dataset.\n",
    "* Creates a simple convolutional neural network.\n",
    "* Configures a DistributedDataParallel strategy.\n",
    "* Runs a training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7780a-c5d8-4058-88ed-656244556f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pytorch_model(parameters):\n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    import torch\n",
    "    import torch.distributed as dist\n",
    "    import torch.nn.functional as F\n",
    "    from torch import nn\n",
    "    from torch.utils.data import DistributedSampler\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "\n",
    "    # Create PyTorch CNN Model.\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "            self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "            self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "            self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = x.view(-1, 4 * 4 * 50)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    # Get dist parameters.\n",
    "    # Kubeflow Training Operator automatically set appropriate RANK and WORLD_SIZE based on the configuration.\n",
    "    RANK = int(os.environ[\"RANK\"])\n",
    "    WORLD_SIZE = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    # IF GPU is available, nccl dist backend is used. Otherwise, gloo dist backend is used.\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        backend = \"nccl\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        backend = \"gloo\"\n",
    "\n",
    "    logging.info(f\"Using Device: {device}, Backend: {backend}\")\n",
    "\n",
    "    model = Net()\n",
    "    # Attach model to the device.\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Attach model to DistributedDataParallel strategy.\n",
    "    dist.init_process_group(backend=\"gloo\", rank=RANK, world_size=WORLD_SIZE)\n",
    "    Distributor = nn.parallel.DistributedDataParallel\n",
    "    model = Distributor(model)\n",
    "\n",
    "    # Get Fashion MNIST Dataset.\n",
    "    dataset = datasets.FashionMNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    )\n",
    "\n",
    "    # Every PyTorchJob worker gets distributed sampler of dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        sampler=DistributedSampler(dataset),\n",
    "    )\n",
    "\n",
    "    # Start Training.\n",
    "    logging.info(f\"Start training for RANK: {RANK}. WORLD_SIZE: {WORLD_SIZE}\")\n",
    "\n",
    "    for epoch in range(int(parameters[\"NUM_EPOCHS\"])):\n",
    "        model.train()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Attach tensors to the device.\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                logging.info(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss={:.4f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(data),\n",
    "                        len(train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    logging.info(\"Training is finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d0042-a33b-4617-853f-bad8b5a08e1d",
   "metadata": {},
   "source": [
    "### Run Training Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d5966-f5bf-47f4-a0a5-5c2f0d857720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set dist env variables to run the above training locally on the Notebook.\n",
    "import os\n",
    "\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"1234\"\n",
    "\n",
    "# Train Model locally in the Notebook.\n",
    "train_pytorch_model({\"NUM_EPOCHS\": \"1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3502e48-9a8d-48e7-abaa-410179f35ec1",
   "metadata": {},
   "source": [
    "### Create & Submit the Distributive Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6adad1-a388-4144-937b-9ec9ebcd3987",
   "metadata": {},
   "source": [
    "You can create PytorchJobs using the Python SDK or by creating a custome resource according to the PytorchJob Kubernetes CRD. In this example we use the Python SDK TrainingClient() class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e19dae-e726-46b0-8236-f99332940f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.training import TrainingClient, constants\n",
    "\n",
    "# Start PyTorchJob Training.\n",
    "pytorchjob_name = \"mnist-distributed-pytorch\"\n",
    "\n",
    "# Since we set `job_kind = PyTorchJob` APIs are going to use PyTorchJob as a default Job kind.\n",
    "training_client = TrainingClient(job_kind=constants.PYTORCHJOB_KIND)\n",
    "\n",
    "training_client.create_job(\n",
    "    name=pytorchjob_name,\n",
    "    base_image=\"pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime\",\n",
    "    train_func=train_pytorch_model,\n",
    "    parameters={\"NUM_EPOCHS\": \"6\"}, # Input parameters for the train function.\n",
    "    num_workers=2,  # How many PyTorch Workers will be created.\n",
    "    resources_per_worker={\"gpu\":1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a13528b-e4fe-43e7-8c34-edfd9a430147",
   "metadata": {},
   "source": [
    "## Check the PyTorchJob Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e40098-ff57-4319-b64e-5ccd5eb29d04",
   "metadata": {},
   "source": [
    "Using Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11219705-c741-40e1-8756-128f4b8f68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorchJob Status: {training_client.is_job_running(name=pytorchjob_name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494704d-445e-4458-8f69-aac3a0ddb1ce",
   "metadata": {},
   "source": [
    "Using Kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79104ad-d148-4263-b6a5-7c7dfa72ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get -o yaml pytorchjobs {pytorchjob_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabcdc01-fbfc-4976-bd64-6be1d0a44166",
   "metadata": {},
   "source": [
    "## Get Pod Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a7e0c-5baa-4e3a-8ab7-101e3db17150",
   "metadata": {},
   "source": [
    "Using Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e9251-e6d3-4376-a0a0-d3a282677b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_client.get_job_pod_names(pytorchjob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c3f44-8cc8-4c7a-a35f-040594a1e2b5",
   "metadata": {},
   "source": [
    "Using Kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb0572-2564-4385-82cc-f7cc948dcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pods -l training.kubeflow.org/job-name={pytorchjob_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc3a151-6601-45df-8195-6d70e0aadab2",
   "metadata": {},
   "source": [
    "## PyTorchJob Training Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faac74d-d626-42be-9dac-70476d01e748",
   "metadata": {},
   "source": [
    "Using Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06788c-fa1f-4f9e-859f-852f1e038fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, _ = training_client.get_job_logs(pytorchjob_name)\n",
    "\n",
    "print(logs[f\"{pytorchjob_name}-master-0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17d475-cf7a-4005-9550-699a08640ff0",
   "metadata": {},
   "source": [
    "Using Kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773ed2f-6dfb-45c3-a39b-7483f218ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl logs -f \"$(kubectl get pods -l training.kubeflow.org/job-name={pytorchjob_name},training.kubeflow.org/replica-type=master,training.kubeflow.org/replica-index=0 -o name)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf960c15-2c91-4a01-bf9a-94e68df35009",
   "metadata": {},
   "source": [
    "## Delete the Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7393b-37e0-4250-ae55-42d55b753237",
   "metadata": {},
   "source": [
    "Using Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306eba8f-bec9-48ac-be6a-d7abf5fc448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_client.delete_job(pytorchjob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927d020-076c-44be-b6c5-8d055e4d5793",
   "metadata": {},
   "source": [
    "Using Kubectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773d855-88c4-459c-bafd-33cf38a433b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete pytorchjob {pytorchjob_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
